---
layout: post
title: "Privacy, Internet & Filter Bubbles: When Technology Backfires."
date: 2021-07-05
author: "Lakshy Sharma"
---

<div style="text-align: center"><img align="center" width="426" height="240" src="/The-Thought-Archive/assets/media/Filter-bubbles.jpg"></div>
<br><br>
The world is changing.
The term 'cyberspace' now includes our physical world. But what we often miss is how the elements of cyberspace that we thought were confined behind the wall of internet are starting to influence our brains, how the elements of cyberspace are starting to change how we think and interact with the physical world. 

In the era where people are willing to give away their privacies for a comfort of few clicks I will try to answer some important questions.
1. How exposed are we on internet?
2. How is Big Tech using our data and why should you care?
3. How much comfort is too much?
<!--display-->

## The Internet and Privacy.

How do you feel when someone over the street looks in your home with binoculars?
If the answer is uncomfortable, Congratulations! You understand the concept of privacy.

Internet brought us together but it also amplified our need to express ourselves. We all like to share our achievements, happiness and thoughts on things we care about with our loved ones. Each one of us has a group of people we trust and know will understand our perspective and not use our words against us. What if someone you don't trust also starts listening these conversations? 

When you sign up for any online messaging based services to talk with people you trust you are essentially inserting a middle man (the host of service) and trusting them not to listen in to the conversation. So if the middle man has all your data, how can you hold them accountable if they start making bad use of it? The privacy policy you just ignored and signed before using the service is your only tool against these service providers and if you did not check it before signing up, I am afraid to say you don't have much in your hands.

So next time you sign up for a service make sure you at-least read an overview of their terms of service and privacy policy, one great online free of charge tool I can find is : <a href= "https://tosdr.org/">https://tosdr.org/</a>. Just input the name of your service and get an overview of their terms of service and privacy policy.

## What is Metadata and how do companies use it?

Now, as we understand why privacy policies are important lets understand another term that is often found in these policies called 'metadata'.

Many companies offering you online messaging services argue that messages you send are protected because they are end to end encrypted and only data they can track is the metadata which according to them is 'harmless'. Some questions I would like to answer in this section are :
- What is metadata?
- Is it really harmless?
- Is usage of your metadata to make money ethical?

### What is Metadata?

Metadata is data about the data. Meaning it contains information like:
1. Who is talking to whom? (Identity of people who are conversing)
2. Where are both the parties talking from? (GPS)
3. What software talking parties are using other than the messaging apps?(Ex:  What OS you are running and other apps.)
4. What is the average length of messages?
5. Time and duration of a conversation.
6. Duration of your calls. (For calling services)

What it does not contain:
1. The actual contents of your message.

### Is metadata really harmless?

Seems pretty harmless right? If someone cannot read actual contents does it mean it is harmless?<br>
Lets look at another case here.<br>
You are talking to people and this time the middleman cannot read contents of the messages but knows who you talked to and for how long. It is ok up-to this point, But now the middleman starts selling this information to other people and starts making money from your metadata!

Q. Why will someone pay for metadata?

A. Just because something is harmless doesn't mean it is worthless.<br>
Metadata might seem harmless to you as a consumer of service but it is a goldmine for advertisers. Information like location, duration of calls, softwares being used can tell a lot about you as a person, which makes it easier for advertisers to target you with ads. Thus, advertisers pay money to the middleman for the metadata they collected.

Note : As a note of caution metadata is not always harmless and if you perform simple google search you will find many instances where FBI has used metadata to track down criminals. Remember- If FBI can use it for legitimate purposes, a person with bad intentions can use it for bad purposes. It is always a good move to find out what a company calls metadata and how they use it, you can find it in their privacy policy.

Discussion about advertisements in a software is a tricky topic that has many point of views and deserves its own post, so I shall not talk more about it here.

### Is the usage of metadata to make money ethical?

*Before we move on* : I don't think it is mine or anyone's business to tell you how your data must be treated,it is always your choice to fix a value to your data. This section will just reflect what I believe and you are free to think otherwise.

To discuss ethics of metadata processing we must understand how it is done.

The metadata is first collected using one or many of following ways:
1. Your app usage.
2. The websites you visit (Browser cookies and trackers)
3. Some companies might be able to get metadata right from your mobile phones based on permissions you have allowed the app.
4. The Mobile phone OS manufacturer might collect data unless you expressly prohibit them from doing so in privacy settings.
5. Tracking your social media behavior. (How many friends you have and who do you talk to most, etc)
6. Some companies may be able to read data from your cloud storages and emails too!
7. There are more methods which I am currently unaware of.

The collected metadata is then sent for processing where groups of 'similar people' are created from the collected data. Once these groups are created and data is organized, the data is auctioned off to organizations that use the data for selling targeted advertisements.

So where do ethics come in here?
- One arguement says that such use of metadata is justified because it can be considered as a payment for the services you have used.
- My arguement is that such use of metadata is only justified if the user knows exactly what data is being taken and where it is being used, also if the service was advertised as 'free' then I do not think selling user data can be justified as a payment.

This is mainly because the data that is being sold to advertisers can be used in other ways than to simply sell ads. It can be used to target politically motivated campaigns to a group of people. The same data can be used for spreading targeted misinformation/mass manipulation that leads to larger misunderstandings and causes mass disruptions.

In short : If there is a legitimate use of data, there is also illegitimate use and I believe the responsibility of informing the customer about what use their data will be put rests with company that is selling the data.

How can targeted marketing lead to mass manipulation you ask?
Ladies and Gentlemen I bring you the Filter Bubbles.

## Filter Bubbles.

Q. What is a filter bubble?
A. A 'filter bubble' is a term used to represent the isolation from views that are opposite in nature to that of a person. Such a situation arises when a person only listens to similar views and refuses to accept an opinion which is different than his/her own.

To understand filter bubbles and how they are created, we must have a closer look at what creates them.

Unlike popular beliefs, filter bubbles are NOT the creation of artificial intelligence. We humans have always lived in types of social filter bubbles. We like making friends that have same intellectual taste as ours. This is nothing to be outrageous about, it is life… We all want peaceful lives and one way to accomplish this is to never listen to dissenting voices or ‘the opposite view’.

The best way to survive is to avoid unnecessary quarrels, this belief has shaped how we humans choose our social circle for a long time.

## Filter Bubbles: What's so evil?

Yes, filter bubbles are natural, but too much of anything is bad. Rampant use of content tailoring technology like artificial intelligence and machine learning algorithms is creating a possibility of mass manipulation by creation of echo chambers.

Today, many companies like to advertise how they can give content that is 'tailored for you' as if that shows how much they care about you. The truth is that we are witnessing uncontrolled personalization of content which is leading to formation of filter bubbles and making it easier for ad companies to target you and remember this targeting is no longer limited to ad companies and can be  used for political campaigning too!

The AI is dividing us, packing us into groups of similar people and showing us only what we want to hear.
It is up-to 'you' the user to stand up and say no to division.

To understand how filter bubbles are formed we need to understand how machine learning algorithms work. There are mainly two methods which can be used for deploying these algorithms which are described below.

### User-history based filtering

User history based filtering works by analyzing the user history and tries to understand what a user 'might like see' in future. Such algorithms show you similar contents to you in future and slowly it pushes you into an echo chamber where people only see posts that are based on what they have seen and liked before. Thereby reinforcing their beliefs to an extent they start believing only they hold the correct opinion.

### Collaborative filtering

This is method of content filtering observes and evaluates patterns of content consumption between similar types of users and then predicts the content which can be recommended to a specific user based on nearest neighbor classification. Eventually, such filters start pushing a group of people into a specific filter category, where they all can be recommended similar contents based on their watch history.

## The harm of too much personalized content.

Lets study a fictional case here.
- The grocery store see you like buying carrots and shows you add about carrots.
- Then the store sells data to other stores and they all start showing you carrots, creepy right? like someone is following you through wires of internet.
- Then the store sells the data to a social media company and then your social media company starts showing you groups of people who like carrots. 
    - *This transitioned from creepy to scary pretty soon,Wow*
- Sooner or later you join a carrot fan group and you see everyone talking about why eggplants are bad, the social media app notices you joined a group that does not like eggplants and soon starts recommending creepy articles that seem to praise carrots and spread hatred against eggplants.
    - *This is point where you should learn about <a href="https://en.wikipedia.org/wiki/Echo_chamber_%28media%29">echo chambers</a>*
- Soon you start disliking eggplants altogether and it seems to you that people who like eggplants are not sane or something...

Of-course, it seems harmless when we talk about carrots and eggplants but how many times have you witnessed a similar situation in politics?A piece of metadata can become the perfect tool to effectively shut-off a person from dissenting views and get them accustomed to reading similar posts all the time.

What makes it even more scary is the fact that articles/groups/people with opposite views are not shown to you as ‘you may not like them'. This can make massive impact on a person’s mind. He/She may soon get intolerant toward the opposite views and maybe they will even start thinking that opposing views don’t make any sense and are outlandish.<br>

Thus, a supposedly helpful algorithm that was meant to show what you may like and make life more easy and comfortable can soon become a weapon which can be used against you. In more straight-forward words.<br>

Filter bubbles can be used to feed a particular opinion to the masses by showing them targeted articles and posts under the garb of 'content tailored for you'. These algorithms can be easily used to brainwash people and sway results of elections! Sensitive population or people who are prone to over-attachment with an organization can be manipulated into believing that their organization is somehow threatened by outside forces.

Filter bubbles are the most effective and silent weapon a person possess in today’s digital world where people are willing to sacrifice privacy for comfort.

## How do we reclaim our privacy and avoid manipulation?

**I do not think going back in time and not using technology is a solution.**

From Governments and law makers.
1. We need to spread awareness about privacy in cyberspace among the consumers and make laws that make it mandatory for companies to tell users what data is being collected and how it will be used, if necessary they must also declare which  organizations are hiding behind the 'third parties' labels in the privacy policies.
2. To combat filter bubbles we must limit use of artificial intelligence and make rule as to how much content filtering is allowed.
3. People must be encouraged to read opposing opinions and social media companies must make sure prolonged targeting of users for ads is not done.

As an individual.
1. One way of avoiding targeted ads is to not like every article you read and only like the articles you think are exceptionally well written and tell the story of every possible perspective.
2. Use ad-blockers whenever possible.
3. Make an effort to understand other side of coin and try to read different types of opinion.
4. Make efforts to read privacy policies before signing up for any internet based services.

Lets use technology and not let it use us.

*Alvida*

Note: If you believe you have found a technical mistake in my blog post please contact me via email.